path_target <- paths[grep("output.html",paths)]
# save/download the report file to local storage
# the file  "maxquant_result_summary.html" now is the report
curl::curl_download(paste0(url_server, path_target), "function_summary.html")
# upload file and do the rendering
# in this case, the proteinGroups.txt is in the working dir. it can be anywhere with the path
# variable r is the returning information from the curl function
#r <- httr::POST(url_api, body = list(file = httr::upload_file("function_data_20190904.csv")))
r <- httr::POST(url_api, body = list(file = httr::upload_file("function_data_20190904.csv"), meta = httr::upload_file("function_meta_20190904.txt")))
r$status_code
url_api <- "http://206.12.91.148/ocpu/library/rmdocpu/R/render_function_file"
# get the root url
url_api_split <- strsplit(url_api, "/")[[1]]
url_server<- paste0(url_api_split[1],"//", url_api_split[3],"/")
# upload file and do the rendering
# in this case, the proteinGroups.txt is in the working dir. it can be anywhere with the path
# variable r is the returning information from the curl function
#r <- httr::POST(url_api, body = list(file = httr::upload_file("function_data_20190904.csv")))
r <- httr::POST(url_api, body = list(file = httr::upload_file("function_data_20190904.csv"), meta = httr::upload_file("function_meta_20190904.txt")))
r$status_code
meta <- "function_meta_20190904.txt"
file <- "function_data_20190904.csv"
#data_table  <- readxl::read_excel(file, sheet = 2) # readin from xl file
data_table <- read.csv(file, header = TRUE, sep = ",")
myfile <- RCurl::getURL("https://raw.githubusercontent.com/ningzhibin/rmdocpu/master/inst/rmd/ML_report_function.Rmd")
writeLines(myfile, con="input.Rmd");
meta_table <- read.delim(meta, header = TRUE, check.names = FALSE, stringsAsFactors = FALSE) # with meta file
meta_table
rmarkdown::render("input.Rmd",output_format = "html_document", params = list(input_datatable =  data_table, meta_table = meta_table), output_file="output.html")
url_api <- "http://206.12.91.148/ocpu/library/rmdocpu/R/render_function_file"
# get the root url
url_api_split <- strsplit(url_api, "/")[[1]]
url_server<- paste0(url_api_split[1],"//", url_api_split[3],"/")
# upload file and do the rendering
# in this case, the proteinGroups.txt is in the working dir. it can be anywhere with the path
# variable r is the returning information from the curl function
#r <- httr::POST(url_api, body = list(file = httr::upload_file("function_data_20190904.csv")))
r <- httr::POST(url_api, body = list(file = httr::upload_file("function_data_20190904.csv"), meta = httr::upload_file("function_meta_20190904.txt")))
r$status_code
r
# upload file and do the rendering
# in this case, the proteinGroups.txt is in the working dir. it can be anywhere with the path
# variable r is the returning information from the curl function
r <- httr::POST(url_api, body = list(file = httr::upload_file("function_data_20190904.csv")))
r
/ocpu/tmp/x03306d75087c78/messages
/ocpu/tmp/x03306d75087c78/console
/ocpu/tmp/x03306d75087c78/info
url_api <- "http://206.12.91.148/ocpu/library/rmdocpu/R/render_function_file"
# get the root url
url_api_split <- strsplit(url_api, "/")[[1]]
url_server<- paste0(url_api_split[1],"//", url_api_split[3],"/")
# upload file and do the rendering
# in this case, the proteinGroups.txt is in the working dir. it can be anywhere with the path
# variable r is the returning information from the curl function
r <- httr::POST(url_api, body = list(file = httr::upload_file("function_data_20190904.csv")))
#r <- httr::POST(url_api, body = list(file = httr::upload_file("function_data_20190904.csv"), meta = httr::upload_file("function_meta_20190904.txt")))
r$status_code
r
file
meta
data_table <- read.csv(file, header = TRUE, sep = ",")
myfile <- RCurl::getURL("https://raw.githubusercontent.com/ningzhibin/rmdocpu/master/inst/rmd/ML_report_function.Rmd")
writeLines(myfile, con="input.Rmd");
rmarkdown::render("input.Rmd",output_format = "html_document", params = list(input_datatable =  data_table), output_file="output.html")
url_api <- "http://206.12.91.148/ocpu/library/rmdocpu/R/render_function_file"
# get the root url
url_api_split <- strsplit(url_api, "/")[[1]]
url_server<- paste0(url_api_split[1],"//", url_api_split[3],"/")
# upload file and do the rendering
# in this case, the proteinGroups.txt is in the working dir. it can be anywhere with the path
# variable r is the returning information from the curl function
r <- httr::POST(url_api, body = list(file = httr::upload_file("function_data_20190904.csv")))
r$status_code
r
# upload file and do the rendering
# in this case, the proteinGroups.txt is in the working dir. it can be anywhere with the path
# variable r is the returning information from the curl function
r <- httr::POST(url_api, body = list(file = httr::upload_file("function_new.csv")))
r
url_api
# upload file and do the rendering
# in this case, the proteinGroups.txt is in the working dir. it can be anywhere with the path
# variable r is the returning information from the curl function
r <- httr::POST(url_api, body = list(file = httr::upload_file("function_new.csv")))
r$status_code
# upload file and do the rendering
# in this case, the proteinGroups.txt is in the working dir. it can be anywhere with the path
# variable r is the returning information from the curl function
r <- httr::POST(url_api, body = list(file = httr::upload_file("function_data_20190904.csv")))
r$status_code
# upload file and do the rendering
# in this case, the proteinGroups.txt is in the working dir. it can be anywhere with the path
# variable r is the returning information from the curl function
#r <- httr::POST(url_api, body = list(file = httr::upload_file("function_data_20190904.csv")))
r <- httr::POST(url_api, body = list(file = httr::upload_file("function_data_20190904.csv"), meta = httr::upload_file("function_meta_20190904.txt")))
r$status_code
paths <- strsplit(rawToChar(r$content), "\n")[[1]]
path_target <- paths[grep("output.html",paths)]
# save/download the report file to local storage
# the file  "maxquant_result_summary.html" now is the report
curl::curl_download(paste0(url_server, path_target), "function_summary.html")
url_api <- "http://206.12.91.148/ocpu/library/rmdocpu/R/render_MQsummary_file"
# get the root url
url_api_split <- strsplit(url_api, "/")[[1]]
url_server<- paste0(url_api_split[1],"//", url_api_split[3],"/")
# upload file and do the rendering
# in this case, the summary.txt is in the working dir. it can be anywhere with the path
# meta file is optional
r <- httr::POST(url_api, body = list(file = httr::upload_file("final_summary.txt")))
#r <- httr::POST(url_api, body = list(file = httr::upload_file("summary1_simple.txt"), meta = httr::upload_file("summary1_meta.txt")))
# get all the paths of all files from the opencpu end, and locate the one, which is the report
# this step needs to be done in the script enviroment
paths <- strsplit(rawToChar(r$content), "\n")[[1]]
path_target <- paths[grep("output.html",paths)]
# save/download the report file to local storage
# the file  "maxquant_result_summary.html" now is the report
curl::curl_download(paste0(url_server, path_target), "maxquant_result_summary.html")
url_api <- "http://206.12.91.148/ocpu/library/rmdocpu/R/render_MQsummary_file"
# get the root url
url_api_split <- strsplit(url_api, "/")[[1]]
url_server<- paste0(url_api_split[1],"//", url_api_split[3],"/")
# upload file and do the rendering
# in this case, the summary.txt is in the working dir. it can be anywhere with the path
# meta file is optional
#r <- httr::POST(url_api, body = list(file = httr::upload_file("final_summary.txt")))
r <- httr::POST(url_api, body = list(file = httr::upload_file("summary1_simple.txt"), meta = httr::upload_file("summary1_meta.txt")))
# get all the paths of all files from the opencpu end, and locate the one, which is the report
# this step needs to be done in the script enviroment
paths <- strsplit(rawToChar(r$content), "\n")[[1]]
path_target <- paths[grep("output.html",paths)]
# save/download the report file to local storage
# the file  "maxquant_result_summary.html" now is the report
curl::curl_download(paste0(url_server, path_target), "maxquant_result_summary.html")
url_api <- "http://206.12.91.148/ocpu/library/rmdocpu/R/render_proteinGroups_file"
# get the root url
url_api_split <- strsplit(url_api, "/")[[1]]
url_server<- paste0(url_api_split[1],"//", url_api_split[3],"/")
# upload file and do the rendering
# in this case, the proteinGroups.txt is in the working dir. it can be anywhere with the path
# variable r is the returning information from the curl function
r <- httr::POST(url_api, body = list(file = httr::upload_file("proteinGroups1.txt"), meta = httr::upload_file("proteinGroups1_meta.txt")))
# get all the paths of all files from the opencpu end, and locate the one, which is the report
# this step needs to be done in the script enviroment
paths <- strsplit(rawToChar(r$content), "\n")[[1]]
path_target <- paths[grep("output.html",paths)]
path_target
# save/download the report file to local storage
# the file  "maxquant_result_summary.html" now is the report
curl::curl_download(paste0(url_server, path_target), "proteinGroups_summary.html")
r
paths
r$url
r$status_code
r$content
paths
url_api <- "http://206.12.91.148/ocpu/library/rmdocpu/R/render_proteinGroups_file"
# get the root url
url_api_split <- strsplit(url_api, "/")[[1]]
url_server<- paste0(url_api_split[1],"//", url_api_split[3],"/")
# upload file and do the rendering
# in this case, the proteinGroups.txt is in the working dir. it can be anywhere with the path
# variable r is the returning information from the curl function
r <- httr::POST(url_api, body = list(file = httr::upload_file("proteinGroups1.txt")))
paths <- strsplit(rawToChar(r$content), "\n")[[1]]
path_target <- paths[grep("output.html",paths)]
paths
# upload file and do the rendering
# in this case, the proteinGroups.txt is in the working dir. it can be anywhere with the path
# variable r is the returning information from the curl function
#r <- httr::POST(url_api, body = list(file = httr::upload_file("proteinGroups1.txt")))
r <- httr::POST(url_api, body = list(file = httr::upload_file("proteinGroups1.txt"), meta = httr::upload_file("proteinGroups1_meta.txt")))
paths <- strsplit(rawToChar(r$content), "\n")[[1]]
path_target <- paths[grep("output.html",paths)]
paths
file <- "proteinGroups1.txt"
meta <- "proteinGroups1_meta.txt"
#data_table  <- readr::read_tsv(file, col_names = TRUE)
data_table  <- read.delim(file, header = TRUE,check.names = FALSE, stringsAsFactors = FALSE) # NOTE the read in options
myfile <- RCurl::getURL("https://raw.githubusercontent.com/ningzhibin/rmdocpu/master/inst/rmd/MQ_report_proteinGroups.Rmd")
writeLines(myfile, con="input.Rmd");
meta_table <- read.delim(meta, header = TRUE, check.names = FALSE, stringsAsFactors = FALSE) # with meta file
rmarkdown::render("input.Rmd",output_format = "html_document", params = list(input_datatable =  data_table, meta_table = meta_table), output_file="output.html")
#r <- httr::POST(url_api, body = list(file = httr::upload_file("proteinGroups1.txt")))
r <- httr::POST(url_api, body = list(file = httr::upload_file("proteinGroups1.txt"), meta = httr::upload_file("proteinGroups1_meta.txt")))
# get all the paths of all files from the opencpu end, and locate the one, which is the report
# this step needs to be done in the script enviroment
paths <- strsplit(rawToChar(r$content), "\n")[[1]]
path_target <- paths[grep("output.html",paths)]
paths
# save/download the report file to local storage
# the file  "maxquant_result_summary.html" now is the report
curl::curl_download(paste0(url_server, path_target), "proteinGroups_summary.html")
r <- httr::POST(url_api, body = list(file = httr::upload_file("proteinGroups1.txt"), meta = httr::upload_file("proteinGroups1_meta.txt")))
# get all the paths of all files from the opencpu end, and locate the one, which is the report
# this step needs to be done in the script enviroment
paths <- strsplit(rawToChar(r$content), "\n")[[1]]
path_target <- paths[grep("output.html",paths)]
paths
# save/download the report file to local storage
# the file  "maxquant_result_summary.html" now is the report
curl::curl_download(paste0(url_server, path_target), "proteinGroups_summary.html")
url_api <- "http://206.12.91.148/ocpu/library/rmdocpu/R/render_peptides_file"
# get the root url
url_api_split <- strsplit(url_api, "/")[[1]]
url_server<- paste0(url_api_split[1],"//", url_api_split[3],"/")
# upload file and do the rendering
# in this case, the proteinGroups.txt is in the working dir. it can be anywhere with the path
# variable r is the returning information from the curl function
#r <- httr::POST(url_api, body = list(file = httr::upload_file("final_peptides.txt")))
r <- httr::POST(url_api, body = list(file = httr::upload_file("peptides3.txt"),meta = httr::upload_file("peptides3_meta.txt")))
r$status_code
# get all the paths of all files from the opencpu end, and locate the one, which is the report
# this step needs to be done in the script enviroment
paths <- strsplit(rawToChar(r$content), "\n")[[1]]
path_target <- paths[grep("output.html",paths)]
path_target
# save/download the report file to local storage
# the file  "maxquant_result_summary.html" now is the report
curl::curl_download(paste0(url_server, path_target), "peptides_summary.html")
url_api <- "http://206.12.91.148/ocpu/library/rmdocpu/R/render_peptides_file"
# get the root url
url_api_split <- strsplit(url_api, "/")[[1]]
url_server<- paste0(url_api_split[1],"//", url_api_split[3],"/")
# upload file and do the rendering
# in this case, the proteinGroups.txt is in the working dir. it can be anywhere with the path
# variable r is the returning information from the curl function
r <- httr::POST(url_api, body = list(file = httr::upload_file("peptides3.txt")))
#r <- httr::POST(url_api, body = list(file = httr::upload_file("peptides3.txt"),meta = httr::upload_file("peptides3_meta.txt")))
r$status_code
# get all the paths of all files from the opencpu end, and locate the one, which is the report
# this step needs to be done in the script enviroment
paths <- strsplit(rawToChar(r$content), "\n")[[1]]
path_target <- paths[grep("output.html",paths)]
path_target
# save/download the report file to local storage
# the file  "maxquant_result_summary.html" now is the report
curl::curl_download(paste0(url_server, path_target), "peptides_summary.html")
file <- "peptides3.txt"
meta <- "peptides3_meta.txt"
data_table  <- read.delim(file, header = TRUE,check.names = FALSE, stringsAsFactors = FALSE) # NOTE the read in options
myfile <- RCurl::getURL("https://raw.githubusercontent.com/ningzhibin/rmdocpu/master/inst/rmd/MQ_report_peptides.Rmd")
writeLines(myfile, con="input.Rmd");
meta_table <- read.delim(meta, header = TRUE, check.names = FALSE, stringsAsFactors = FALSE) #with meta file
rmarkdown::render("input.Rmd",output_format = "html_document", params = list(input_datatable =  data_table, meta_table = meta_table), output_file="output.html")
file <- "peptides1.txt"
meta <- "peptides1_meta.txt"
data_table  <- read.delim(file, header = TRUE,check.names = FALSE, stringsAsFactors = FALSE) # NOTE the read in options
myfile <- RCurl::getURL("https://raw.githubusercontent.com/ningzhibin/rmdocpu/master/inst/rmd/MQ_report_peptides.Rmd")
writeLines(myfile, con="input.Rmd");
if(!is.null(meta)){
meta_table <- read.delim(meta, header = TRUE, check.names = FALSE, stringsAsFactors = FALSE) #with meta file
rmarkdown::render("input.Rmd",output_format = "html_document", params = list(input_datatable =  data_table, meta_table = meta_table), output_file="output.html")
}else{
rmarkdown::render("input.Rmd",output_format = "html_document", params = list(input_datatable =  data_table), output_file="output.html")
}
meta_table <- read.delim(meta, header = TRUE, check.names = FALSE, stringsAsFactors = FALSE) #with meta file
meta
getwd()
meta
url_api
# upload file and do the rendering
# in this case, the proteinGroups.txt is in the working dir. it can be anywhere with the path
# variable r is the returning information from the curl function
#r <- httr::POST(url_api, body = list(file = httr::upload_file("peptides3.txt")))
r <- httr::POST(url_api, body = list(file = httr::upload_file("peptides3.txt"),meta = httr::upload_file("peptides3_meta.txt")))
r
?timeout
r <- httr::POST(url_api, body = list(file = httr::upload_file("peptides3.txt"),meta = httr::upload_file("peptides3_meta.txt")), timeout(200))
r$status_code
# upload file and do the rendering
# in this case, the proteinGroups.txt is in the working dir. it can be anywhere with the path
# variable r is the returning information from the curl function
#r <- httr::POST(url_api, body = list(file = httr::upload_file("peptides3.txt")))
r <- httr::POST(url_api, body = list(file = httr::upload_file("peptides3.txt"),meta = httr::upload_file("peptides3_meta.txt")), httr::timeout(200))
r$status_code
r
httr::timeout(200)
# upload file and do the rendering
# in this case, the proteinGroups.txt is in the working dir. it can be anywhere with the path
# variable r is the returning information from the curl function
#r <- httr::POST(url_api, body = list(file = httr::upload_file("peptides3.txt")))
r <- httr::POST(url_api, body = list(file = httr::upload_file("peptides3.txt"),meta = httr::upload_file("peptides3_meta.txt")), httr::timeout(1e+07))
# upload file and do the rendering
# in this case, the proteinGroups.txt is in the working dir. it can be anywhere with the path
# variable r is the returning information from the curl function
#r <- httr::POST(url_api, body = list(file = httr::upload_file("peptides3.txt")))
r <- httr::POST(url_api, body = list(file = httr::upload_file("peptides3.txt"),meta = httr::upload_file("peptides3_meta.txt")), httr::timeout(200000))
r
paths <- strsplit(rawToChar(r$content), "\n")[[1]]
path_target <- paths[grep("output.html",paths)]
path_target
# save/download the report file to local storage
# the file  "maxquant_result_summary.html" now is the report
curl::curl_download(paste0(url_server, path_target), "peptides_summary.html")
url_api <- "http://206.12.91.148/ocpu/library/rmdocpu/R/render_taxon_file"
# get the root url
url_api_split <- strsplit(url_api, "/")[[1]]
url_server<- paste0(url_api_split[1],"//", url_api_split[3],"/")
# upload file and do the rendering
# in this case, the proteinGroups.txt is in the working dir. it can be anywhere with the path
# variable r is the returning information from the curl function
r <- httr::POST(url_api, body = list(file = httr::upload_file("BuiltIn.taxa.refine.csv")))
# get all the paths of all files from the opencpu end, and locate the one, which is the report
# this step needs to be done in the script enviroment
paths <- strsplit(rawToChar(r$content), "\n")[[1]]
path_target <- paths[grep("output.html",paths)]
# save/download the report file to local storage
# the file  "maxquant_result_summary.html" now is the report
curl::curl_download(paste0(url_server, path_target), "report_taxonomy_summary.html")
r
url_api <- "http://206.12.91.148/ocpu/library/rmdocpu/R/render_function_file"
# get the root url
url_api_split <- strsplit(url_api, "/")[[1]]
url_server<- paste0(url_api_split[1],"//", url_api_split[3],"/")
# upload file and do the rendering
# in this case, the proteinGroups.txt is in the working dir. it can be anywhere with the path
# variable r is the returning information from the curl function
#r <- httr::POST(url_api, body = list(file = httr::upload_file("function_data_20190904.csv")))
r <- httr::POST(url_api, body = list(file = httr::upload_file("function_data_20190904.csv"), meta = httr::upload_file("function_meta_20190904.txt")))
r$status_code
# get all the paths of all files from the opencpu end, and locate the one, which is the report
# this step needs to be done in the script enviroment
paths <- strsplit(rawToChar(r$content), "\n")[[1]]
path_target <- paths[grep("output.html",paths)]
# save/download the report file to local storage
# the file  "maxquant_result_summary.html" now is the report
curl::curl_download(paste0(url_server, path_target), "function_summary.html")
?try
runApp('C:/Users/Figeys Lab/Dropbox/Project_MetaLab/shiny_apps/multivariable_analysis2')
library(selectize)
url_api <- "http://206.12.91.148/ocpu/library/rmdocpu/R/render_function_file"
# get the root url
url_api_split <- strsplit(url_api, "/")[[1]]
url_server<- paste0(url_api_split[1],"//", url_api_split[3],"/")
# upload file and do the rendering
# in this case, the proteinGroups.txt is in the working dir. it can be anywhere with the path
# variable r is the returning information from the curl function
#r <- httr::POST(url_api, body = list(file = httr::upload_file("functions.csv")))
r <- httr::POST(url_api, body = list(file = httr::upload_file("functions.csv"), meta = httr::upload_file("metadata.txt")))
r$status_code
# get all the paths of all files from the opencpu end, and locate the one, which is the report
# this step needs to be done in the script enviroment
paths <- strsplit(rawToChar(r$content), "\n")[[1]]
path_target <- paths[grep("output.html",paths)]
# save/download the report file to local storage
# the file  "maxquant_result_summary.html" now is the report
curl::curl_download(paste0(url_server, path_target), "report_function_summary.html")
url_api <- "http://206.12.91.148/ocpu/library/rmdocpu/R/render_function_file"
# get the root url
url_api_split <- strsplit(url_api, "/")[[1]]
url_server<- paste0(url_api_split[1],"//", url_api_split[3],"/")
# upload file and do the rendering
# in this case, the proteinGroups.txt is in the working dir. it can be anywhere with the path
# variable r is the returning information from the curl function
#r <- httr::POST(url_api, body = list(file = httr::upload_file("functions.csv")))
r <- httr::POST(url_api, body = list(file = httr::upload_file("functions.csv"), meta = httr::upload_file("metadata.txt")))
r$status_code
# get all the paths of all files from the opencpu end, and locate the one, which is the report
# this step needs to be done in the script enviroment
paths <- strsplit(rawToChar(r$content), "\n")[[1]]
path_target <- paths[grep("output.html",paths)]
# save/download the report file to local storage
# the file  "maxquant_result_summary.html" now is the report
curl::curl_download(paste0(url_server, path_target), "report_function_summary.html")
# upload file and do the rendering
# in this case, the proteinGroups.txt is in the working dir. it can be anywhere with the path
# variable r is the returning information from the curl function
#r <- httr::POST(url_api, body = list(file = httr::upload_file("functions.csv")))
r <- httr::POST(url_api, body = list(file = httr::upload_file("functions.csv"), meta = httr::upload_file("metadata.txt")))
setwd("C:/Users/Figeys Lab/Dropbox/Project_R_packages/rmdocpu/inst/rmd")
url_api <- "http://206.12.91.148/ocpu/library/rmdocpu/R/render_function_file"
# get the root url
url_api_split <- strsplit(url_api, "/")[[1]]
url_server<- paste0(url_api_split[1],"//", url_api_split[3],"/")
# upload file and do the rendering
# in this case, the proteinGroups.txt is in the working dir. it can be anywhere with the path
# variable r is the returning information from the curl function
#r <- httr::POST(url_api, body = list(file = httr::upload_file("functions.csv")))
r <- httr::POST(url_api, body = list(file = httr::upload_file("functions.csv"), meta = httr::upload_file("metadata.txt")))
r$status_code
# get all the paths of all files from the opencpu end, and locate the one, which is the report
# this step needs to be done in the script enviroment
paths <- strsplit(rawToChar(r$content), "\n")[[1]]
path_target <- paths[grep("output.html",paths)]
# save/download the report file to local storage
# the file  "maxquant_result_summary.html" now is the report
curl::curl_download(paste0(url_server, path_target), "report_function_summary.html")
source("https://raw.githubusercontent.com/ningzhibin/rmdocpu/master/inst/subfunctions_general.r")
source("https://raw.githubusercontent.com/ningzhibin/rmdocpu/master/inst/subfunctions_general_update.r")
# enviroment setup
knitr::opts_chunk$set(echo = FALSE,warning = FALSE, message = FALSE, cache = FALSE)
library(tidyverse)
library(ggplot2)
library(plotly)
library(readxl)
library(pheatmap)
library(reshape2)
library(vegan)
library(ggdendro)
# library(gridExtra)
#library(plotly)
# library(DT)
# for interactive data table display
# local usage test and debug
# rmarkdown::render("MQ_report_function_ocpu.Rmd", params = list(summary_file_tbl =  your_readin_tbl))
# on local machine, your_readin_tbl is a data table, while on ocpu, your_readin_tbl is a json formatted table
# todo
# check the metafile, if meta is not qualified, do not use it.
# version control
# 20190821 created function rmd
# 20190904 added heatmap and PCA, can show meta info if provided
# test with local test with local files in the same dir,
data_fun <- read.csv("functions.csv", header = TRUE, sep = ",")
head(data_fun)
if(is.null(params$input_datatable)){
# test with local test with local files in the same dir,
data_fun <- read.csv("functions.csv", header = TRUE, sep = ",")
}else{
# opencpu render from data table by parametrized input
data_fun <- params$input_datatable
}
# Note: The folling analysis with meta info assumes that
# 1st columns as sample name, 2nd column as experiment name, 3rd column and after as grouping
meta_table <- params$meta_table
eta_table <- read.delim("metadata.txt", header = TRUE, check.names = FALSE, stringsAsFactors = FALSE)
meta_table <- read.delim("metadata.txt", header = TRUE, check.names = FALSE, stringsAsFactors = FALSE)
meta_table
if(any(grepl("intensity.", colnames(data_fun), ignore.case=TRUE))){
intensity_columns <- data_fun[,grep("intensity.", colnames(data_fun), ignore.case=TRUE), drop = FALSE]
colnames(intensity_columns)<-gsub("intensity.", "", colnames(intensity_columns), ignore.case=TRUE)
}
# Calculate subtotal for each category
intensity_columns_C <- cbind(data_fun$COG.category, intensity_columns)
data_fun_COG <- aggregate(. ~ data_fun$COG.category, data = intensity_columns_C[,-1, drop = FALSE], FUN = sum)
data_fun_COG$`data_fun$COG.category` <- as.character(data_fun_COG$`data_fun$COG.category`)
data_fun_COG$`data_fun$COG.category`[1] <- "Unmatched"
data_fun_COG <- data_fun_COG[which(rowSums(data_fun_COG[,-1,drop =  FALSE])>0),]
# Prepare data for plotting
Intensity <- rowSums(data_fun_COG[,-1, drop = FALSE])
rowSum_COG <- as.data.frame(Intensity)
COG_cat <- data_fun_COG[,1]
rowSum_COG <- cbind(COG_cat, rowSum_COG)
Intensity
head(intensity_columns)
head(Intensity)
meta_table$meta1
is.na(meta_table$meta1)
any(is.na(meta_table$meta1))
url_api <- "http://206.12.91.148/ocpu/library/rmdocpu/R/render_function_file"
# get the root url
url_api_split <- strsplit(url_api, "/")[[1]]
url_server<- paste0(url_api_split[1],"//", url_api_split[3],"/")
# upload file and do the rendering
# in this case, the proteinGroups.txt is in the working dir. it can be anywhere with the path
# variable r is the returning information from the curl function
#r <- httr::POST(url_api, body = list(file = httr::upload_file("functions.csv")))
r <- httr::POST(url_api, body = list(file = httr::upload_file("functions.csv"), meta = httr::upload_file("metadata.txt")))
r$status_code
# get all the paths of all files from the opencpu end, and locate the one, which is the report
# this step needs to be done in the script enviroment
paths <- strsplit(rawToChar(r$content), "\n")[[1]]
path_target <- paths[grep("output.html",paths)]
# save/download the report file to local storage
# the file  "maxquant_result_summary.html" now is the report
curl::curl_download(paste0(url_server, path_target), "report_function_summary.html")
?image
?imag
library(htmltools)
?img
unlink('ML_report_function_cache', recursive = TRUE)
url_api <- "http://206.12.91.148/ocpu/library/rmdocpu/R/render_MQsummary_file"
# get the root url
url_api_split <- strsplit(url_api, "/")[[1]]
url_server<- paste0(url_api_split[1],"//", url_api_split[3],"/")
# upload file and do the rendering
# in this case, the summary.txt is in the working dir. it can be anywhere with the path
# meta file is optional
#r <- httr::POST(url_api, body = list(file = httr::upload_file("final_summary.txt")))
r <- httr::POST(url_api, body = list(file = httr::upload_file("summary1_simple.txt"), meta = httr::upload_file("summary1_meta.txt")))
# get all the paths of all files from the opencpu end, and locate the one, which is the report
# this step needs to be done in the script enviroment
paths <- strsplit(rawToChar(r$content), "\n")[[1]]
path_target <- paths[grep("output.html",paths)]
# save/download the report file to local storage
# the file  "maxquant_result_summary.html" now is the report
curl::curl_download(paste0(url_server, path_target), "report_ID_summary.html")
url_api <- "http://206.12.91.148/ocpu/library/rmdocpu/R/render_function_file"
# get the root url
url_api_split <- strsplit(url_api, "/")[[1]]
url_server<- paste0(url_api_split[1],"//", url_api_split[3],"/")
# upload file and do the rendering
# in this case, the proteinGroups.txt is in the working dir. it can be anywhere with the path
# variable r is the returning information from the curl function
#r <- httr::POST(url_api, body = list(file = httr::upload_file("functions.csv")))
r <- httr::POST(url_api, body = list(file = httr::upload_file("functions.csv"), meta = httr::upload_file("metadata.txt")))
r$status_code
# get all the paths of all files from the opencpu end, and locate the one, which is the report
# this step needs to be done in the script enviroment
paths <- strsplit(rawToChar(r$content), "\n")[[1]]
path_target <- paths[grep("output.html",paths)]
# save/download the report file to local storage
# the file  "maxquant_result_summary.html" now is the report
curl::curl_download(paste0(url_server, path_target), "report_function_summary.html")
shiny::runApp('Z:/Microbiome/shiny_apps/peptide_centric/Shiny_wrapper')
setwd("Z:/Microbiome/shiny_apps/peptide_centric/Shiny_wrapper")
runApp()
runApp()
shiny::runApp('Z:/Microbiome/shiny_apps/peptide_centric/Shiny_wrapper')
shiny::runApp('Z:/Microbiome/shiny_apps/peptide_centric/Shiny_wrapper')
shiny::runApp('Z:/Microbiome/shiny_apps/peptide_centric/Shiny_wrapper')
shiny::runApp('Z:/Microbiome/shiny_apps/peptide_centric/Shiny_wrapper')
