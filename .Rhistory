# therefore it's marked here if there is any inconcistency
}
}
PostHoc<-function(vector, factor, p_threshold = 0.05){
p.value_anova <- anova(lm(as.numeric(vector)~as.factor(factor)))$Pr[1]
if(p.value_anova < 0.05){
p_PostHoc_matrix <- pairwise.t.test(as.numeric(vector),as.factor(factor),p.adj = "fdr")$p.value
p_PostHoc_pairs <- find_p_location(p_PostHoc_matrix, p_threshold = p_threshold) # find_p_location is the self define functions
return(paste0("ANOVA p=",p.value_anova,";",p_PostHoc_pairs))
# return(p_PostHoc_pairs)
}else{
return(NA)
}
}
pvalues_anova <- matrix_PostHoc(df_intensity,meta_table[,3])
head(pvalues_anova)
?anova
df_intensity[1,]
df_intensity[1,] ->r
factor <- meta_table[,3]
vector <-r
p.value_anova <- anova(lm(as.numeric(vector)~as.factor(factor)))$Pr[1]
p.value_anova
pairwise.t.test(as.numeric(vector),as.factor(factor),p.adj = "fdr")$p.value
pairwise.t.test(as.numeric(vector),as.factor(factor))$p.value
pairwise.t.test(vector,factor)
pairwise.t.test(as.numeric(vector),as.factor(factor))$p.value
factor
pairwise.t.test(as.numeric(vector),factor)
vector
class(vector)
class(r)
v<- as.vector(vector)
v
class(v)
?pairwise.t.test
Ozone
r
class(v)
?as.vector
as.numeric(r)
pairwise.t.test(as.numeric(vector),as.factor(factor),p.adj = "fdr")
pairwise.t.test(as.numeric(vector),factor)
pairwise.t.test(as.numeric(df_intensity[,2]),factor)
pairwise.t.test(as.numeric(df_intensity[2,]),factor)
pairwise.t.test(as.numeric(df_intensity[3,]),factor)
?pairwise.t.test
pairwise.t.test(Ozone, Month)
factor
Month
Ozone
n <- 1000
for(i in 1:n){
i
}
for(i in 1:n){
print(i)
}
for(i in 1:n){
print(i)
}
n <- 10000
for(i in 1:n){
print(i)
}
n <- 100000
for(i in 1:n){
print(i)
}
n <- 1000000
for(i in 1:n){
print(i)
}
n <- 1000
system.time(for(i in 1:n){
print(i)
})
n <- 10000
system.time(for(i in 1:n){
print(i)
})
system.time(for(i in 1:n){
print(i)
})
n <- 1000000
system.time(for(i in 1:n){
print(i)
})
n <- 1000
n
1:100
1:n
knitr::opts_chunk$set(echo = FALSE,warning = FALSE, message = FALSE, cache = FALSE)
library(canvasXpress)
y <- read.table("http://www.canvasxpress.org/data/cX-irist-dat.txt", header=TRUE, sep="\t",
quote="", row.names=1, fill=TRUE, check.names=FALSE, stringsAsFactors=FALSE)
# 读取分组信息
z <- read.table("http://www.canvasxpress.org/data/cX-irist-var.txt", header=TRUE, sep= "\t",
quote="", row.names=1, fill=TRUE, check.names=FALSE, stringsAsFactors=FALSE)
canvasXpress(data              = y,
varAnnot          = z,
graphType         = "Scatter2D",
scatterPlotMatrix = TRUE,
colorBy           = "Species",
showTransition    = TRUE)
vignette(package = "canvasXpress")
library(canvasXpress)
vignette(package = "canvasXpress")
vignette("getting_started", package = "canvasXpress")
vignette("additional_examples", package = "canvasXpress")
cxShinyExample()
cxShinyExample(example = "example1")
nodes
nodes=read.table("http://www.canvasxpress.org/data/cX-lesmiserable-nodes.txt", header=TRUE, sep="\t", quote="", fill=TRUE, check.names=FALSE, stringsAsFactors=FALSE)
edges=read.table("http://www.canvasxpress.org/data/cX-lesmiserable-edges.txt", header=TRUE, sep="\t", quote="", fill=TRUE, check.names=FALSE, stringsAsFactors=FALSE)
nodes
edges
?networkLayoutType
http://www.canvasxpress.org/html/radar-8.html
library(plotly)
knitr::opts_chunk$set(echo = FALSE)
plotly::ggplotly(1,1)
plotly::plotly(1,1)
?plotly
plotly::plot_ly(1,1)
plotly::plot_ly(x = 1, y = 1)
y=read.table("http://www.canvasxpress.org/data/cX-generic-dat.txt", header=TRUE, sep="\t", quote="", row.names=1, fill=TRUE, check.names=FALSE, stringsAsFactors=FALSE)
x=read.table("http://www.canvasxpress.org/data/cX-generic-smp.txt", header=TRUE, sep="\t", quote="", row.names=1, fill=TRUE, check.names=FALSE, stringsAsFactors=FALSE)
z=read.table("http://www.canvasxpress.org/data/cX-generic-var.txt", header=TRUE, sep="\t", quote="", row.names=1, fill=TRUE, check.names=FALSE, stringsAsFactors=FALSE)
canvasXpress(
data=y,
smpAnnot=x,
varAnnot=z,
circularArc=360,
circularRotate=0,
circularType="radar",
colorScheme="Bootstrap",
graphType="Circular",
ringGraphType=list("line"),
showTransition=TRUE,
smpOverlays=list("Factor3", "-", "Factor1", "Factor2"),
title="Radar with Overlays",
transitionStep=50,
transitionTime=1500
)
url_api <- "http://206.12.91.148/ocpu/library/rmdocpu/R/render_function_file"
# get the root url
url_api_split <- strsplit(url_api, "/")[[1]]
url_server<- paste0(url_api_split[1],"//", url_api_split[3],"/")
# upload file and do the rendering
# in this case, the proteinGroups.txt is in the working dir. it can be anywhere with the path
# variable r is the returning information from the curl function
#r <- httr::POST(url_api, body = list(file = httr::upload_file("function_data_20190904")))
r <- httr::POST(url_api, body = list(file = httr::upload_file("function_data_20190904"), meta = httr::upload_file("function_meta_20190904.txt")))
# get all the paths of all files from the opencpu end, and locate the one, which is the report
# this step needs to be done in the script enviroment
paths <- strsplit(rawToChar(r$content), "\n")[[1]]
path_target <- paths[grep("output.html",paths)]
# save/download the report file to local storage
# the file  "maxquant_result_summary.html" now is the report
curl::curl_download(paste0(url_server, path_target), "function_summary.html")
url_api <- "http://206.12.91.148/ocpu/library/rmdocpu/R/render_function_file"
# get the root url
url_api_split <- strsplit(url_api, "/")[[1]]
url_server<- paste0(url_api_split[1],"//", url_api_split[3],"/")
# upload file and do the rendering
# in this case, the proteinGroups.txt is in the working dir. it can be anywhere with the path
# variable r is the returning information from the curl function
r <- httr::POST(url_api, body = list(file = httr::upload_file("function_data_20190904")))
setwd("C:/Users/Figeys Lab/Dropbox/Project_R_packages/rmdocpu/inst/rmd")
# upload file and do the rendering
# in this case, the proteinGroups.txt is in the working dir. it can be anywhere with the path
# variable r is the returning information from the curl function
r <- httr::POST(url_api, body = list(file = httr::upload_file("function_data_20190904")))
getwd()
# upload file and do the rendering
# in this case, the proteinGroups.txt is in the working dir. it can be anywhere with the path
# variable r is the returning information from the curl function
r <- httr::POST(url_api, body = list(file = httr::upload_file("function_data_20190904.csv")))
r$status_code
paths <- strsplit(rawToChar(r$content), "\n")[[1]]
path_target <- paths[grep("output.html",paths)]
# save/download the report file to local storage
# the file  "maxquant_result_summary.html" now is the report
curl::curl_download(paste0(url_server, path_target), "function_summary.html")
# upload file and do the rendering
# in this case, the proteinGroups.txt is in the working dir. it can be anywhere with the path
# variable r is the returning information from the curl function
#r <- httr::POST(url_api, body = list(file = httr::upload_file("function_data_20190904.csv")))
r <- httr::POST(url_api, body = list(file = httr::upload_file("function_data_20190904.csv"), meta = httr::upload_file("function_meta_20190904.txt")))
r$status_code
url_api <- "http://206.12.91.148/ocpu/library/rmdocpu/R/render_function_file"
# get the root url
url_api_split <- strsplit(url_api, "/")[[1]]
url_server<- paste0(url_api_split[1],"//", url_api_split[3],"/")
# upload file and do the rendering
# in this case, the proteinGroups.txt is in the working dir. it can be anywhere with the path
# variable r is the returning information from the curl function
#r <- httr::POST(url_api, body = list(file = httr::upload_file("function_data_20190904.csv")))
r <- httr::POST(url_api, body = list(file = httr::upload_file("function_data_20190904.csv"), meta = httr::upload_file("function_meta_20190904.txt")))
r$status_code
meta <- "function_meta_20190904.txt"
file <- "function_data_20190904.csv"
#data_table  <- readxl::read_excel(file, sheet = 2) # readin from xl file
data_table <- read.csv(file, header = TRUE, sep = ",")
myfile <- RCurl::getURL("https://raw.githubusercontent.com/ningzhibin/rmdocpu/master/inst/rmd/ML_report_function.Rmd")
writeLines(myfile, con="input.Rmd");
meta_table <- read.delim(meta, header = TRUE, check.names = FALSE, stringsAsFactors = FALSE) # with meta file
meta_table
rmarkdown::render("input.Rmd",output_format = "html_document", params = list(input_datatable =  data_table, meta_table = meta_table), output_file="output.html")
url_api <- "http://206.12.91.148/ocpu/library/rmdocpu/R/render_function_file"
# get the root url
url_api_split <- strsplit(url_api, "/")[[1]]
url_server<- paste0(url_api_split[1],"//", url_api_split[3],"/")
# upload file and do the rendering
# in this case, the proteinGroups.txt is in the working dir. it can be anywhere with the path
# variable r is the returning information from the curl function
#r <- httr::POST(url_api, body = list(file = httr::upload_file("function_data_20190904.csv")))
r <- httr::POST(url_api, body = list(file = httr::upload_file("function_data_20190904.csv"), meta = httr::upload_file("function_meta_20190904.txt")))
r$status_code
r
# upload file and do the rendering
# in this case, the proteinGroups.txt is in the working dir. it can be anywhere with the path
# variable r is the returning information from the curl function
r <- httr::POST(url_api, body = list(file = httr::upload_file("function_data_20190904.csv")))
r
/ocpu/tmp/x03306d75087c78/messages
/ocpu/tmp/x03306d75087c78/console
/ocpu/tmp/x03306d75087c78/info
url_api <- "http://206.12.91.148/ocpu/library/rmdocpu/R/render_function_file"
# get the root url
url_api_split <- strsplit(url_api, "/")[[1]]
url_server<- paste0(url_api_split[1],"//", url_api_split[3],"/")
# upload file and do the rendering
# in this case, the proteinGroups.txt is in the working dir. it can be anywhere with the path
# variable r is the returning information from the curl function
r <- httr::POST(url_api, body = list(file = httr::upload_file("function_data_20190904.csv")))
#r <- httr::POST(url_api, body = list(file = httr::upload_file("function_data_20190904.csv"), meta = httr::upload_file("function_meta_20190904.txt")))
r$status_code
r
file
meta
data_table <- read.csv(file, header = TRUE, sep = ",")
myfile <- RCurl::getURL("https://raw.githubusercontent.com/ningzhibin/rmdocpu/master/inst/rmd/ML_report_function.Rmd")
writeLines(myfile, con="input.Rmd");
rmarkdown::render("input.Rmd",output_format = "html_document", params = list(input_datatable =  data_table), output_file="output.html")
url_api <- "http://206.12.91.148/ocpu/library/rmdocpu/R/render_function_file"
# get the root url
url_api_split <- strsplit(url_api, "/")[[1]]
url_server<- paste0(url_api_split[1],"//", url_api_split[3],"/")
# upload file and do the rendering
# in this case, the proteinGroups.txt is in the working dir. it can be anywhere with the path
# variable r is the returning information from the curl function
r <- httr::POST(url_api, body = list(file = httr::upload_file("function_data_20190904.csv")))
r$status_code
r
# upload file and do the rendering
# in this case, the proteinGroups.txt is in the working dir. it can be anywhere with the path
# variable r is the returning information from the curl function
r <- httr::POST(url_api, body = list(file = httr::upload_file("function_new.csv")))
r
url_api
# upload file and do the rendering
# in this case, the proteinGroups.txt is in the working dir. it can be anywhere with the path
# variable r is the returning information from the curl function
r <- httr::POST(url_api, body = list(file = httr::upload_file("function_new.csv")))
r$status_code
# upload file and do the rendering
# in this case, the proteinGroups.txt is in the working dir. it can be anywhere with the path
# variable r is the returning information from the curl function
r <- httr::POST(url_api, body = list(file = httr::upload_file("function_data_20190904.csv")))
r$status_code
# upload file and do the rendering
# in this case, the proteinGroups.txt is in the working dir. it can be anywhere with the path
# variable r is the returning information from the curl function
#r <- httr::POST(url_api, body = list(file = httr::upload_file("function_data_20190904.csv")))
r <- httr::POST(url_api, body = list(file = httr::upload_file("function_data_20190904.csv"), meta = httr::upload_file("function_meta_20190904.txt")))
r$status_code
paths <- strsplit(rawToChar(r$content), "\n")[[1]]
path_target <- paths[grep("output.html",paths)]
# save/download the report file to local storage
# the file  "maxquant_result_summary.html" now is the report
curl::curl_download(paste0(url_server, path_target), "function_summary.html")
url_api <- "http://206.12.91.148/ocpu/library/rmdocpu/R/render_MQsummary_file"
# get the root url
url_api_split <- strsplit(url_api, "/")[[1]]
url_server<- paste0(url_api_split[1],"//", url_api_split[3],"/")
# upload file and do the rendering
# in this case, the summary.txt is in the working dir. it can be anywhere with the path
# meta file is optional
r <- httr::POST(url_api, body = list(file = httr::upload_file("final_summary.txt")))
#r <- httr::POST(url_api, body = list(file = httr::upload_file("summary1_simple.txt"), meta = httr::upload_file("summary1_meta.txt")))
# get all the paths of all files from the opencpu end, and locate the one, which is the report
# this step needs to be done in the script enviroment
paths <- strsplit(rawToChar(r$content), "\n")[[1]]
path_target <- paths[grep("output.html",paths)]
# save/download the report file to local storage
# the file  "maxquant_result_summary.html" now is the report
curl::curl_download(paste0(url_server, path_target), "maxquant_result_summary.html")
url_api <- "http://206.12.91.148/ocpu/library/rmdocpu/R/render_MQsummary_file"
# get the root url
url_api_split <- strsplit(url_api, "/")[[1]]
url_server<- paste0(url_api_split[1],"//", url_api_split[3],"/")
# upload file and do the rendering
# in this case, the summary.txt is in the working dir. it can be anywhere with the path
# meta file is optional
#r <- httr::POST(url_api, body = list(file = httr::upload_file("final_summary.txt")))
r <- httr::POST(url_api, body = list(file = httr::upload_file("summary1_simple.txt"), meta = httr::upload_file("summary1_meta.txt")))
# get all the paths of all files from the opencpu end, and locate the one, which is the report
# this step needs to be done in the script enviroment
paths <- strsplit(rawToChar(r$content), "\n")[[1]]
path_target <- paths[grep("output.html",paths)]
# save/download the report file to local storage
# the file  "maxquant_result_summary.html" now is the report
curl::curl_download(paste0(url_server, path_target), "maxquant_result_summary.html")
url_api <- "http://206.12.91.148/ocpu/library/rmdocpu/R/render_proteinGroups_file"
# get the root url
url_api_split <- strsplit(url_api, "/")[[1]]
url_server<- paste0(url_api_split[1],"//", url_api_split[3],"/")
# upload file and do the rendering
# in this case, the proteinGroups.txt is in the working dir. it can be anywhere with the path
# variable r is the returning information from the curl function
r <- httr::POST(url_api, body = list(file = httr::upload_file("proteinGroups1.txt"), meta = httr::upload_file("proteinGroups1_meta.txt")))
# get all the paths of all files from the opencpu end, and locate the one, which is the report
# this step needs to be done in the script enviroment
paths <- strsplit(rawToChar(r$content), "\n")[[1]]
path_target <- paths[grep("output.html",paths)]
path_target
# save/download the report file to local storage
# the file  "maxquant_result_summary.html" now is the report
curl::curl_download(paste0(url_server, path_target), "proteinGroups_summary.html")
r
paths
r$url
r$status_code
r$content
paths
url_api <- "http://206.12.91.148/ocpu/library/rmdocpu/R/render_proteinGroups_file"
# get the root url
url_api_split <- strsplit(url_api, "/")[[1]]
url_server<- paste0(url_api_split[1],"//", url_api_split[3],"/")
# upload file and do the rendering
# in this case, the proteinGroups.txt is in the working dir. it can be anywhere with the path
# variable r is the returning information from the curl function
r <- httr::POST(url_api, body = list(file = httr::upload_file("proteinGroups1.txt")))
paths <- strsplit(rawToChar(r$content), "\n")[[1]]
path_target <- paths[grep("output.html",paths)]
paths
# upload file and do the rendering
# in this case, the proteinGroups.txt is in the working dir. it can be anywhere with the path
# variable r is the returning information from the curl function
#r <- httr::POST(url_api, body = list(file = httr::upload_file("proteinGroups1.txt")))
r <- httr::POST(url_api, body = list(file = httr::upload_file("proteinGroups1.txt"), meta = httr::upload_file("proteinGroups1_meta.txt")))
paths <- strsplit(rawToChar(r$content), "\n")[[1]]
path_target <- paths[grep("output.html",paths)]
paths
file <- "proteinGroups1.txt"
meta <- "proteinGroups1_meta.txt"
#data_table  <- readr::read_tsv(file, col_names = TRUE)
data_table  <- read.delim(file, header = TRUE,check.names = FALSE, stringsAsFactors = FALSE) # NOTE the read in options
myfile <- RCurl::getURL("https://raw.githubusercontent.com/ningzhibin/rmdocpu/master/inst/rmd/MQ_report_proteinGroups.Rmd")
writeLines(myfile, con="input.Rmd");
meta_table <- read.delim(meta, header = TRUE, check.names = FALSE, stringsAsFactors = FALSE) # with meta file
rmarkdown::render("input.Rmd",output_format = "html_document", params = list(input_datatable =  data_table, meta_table = meta_table), output_file="output.html")
#r <- httr::POST(url_api, body = list(file = httr::upload_file("proteinGroups1.txt")))
r <- httr::POST(url_api, body = list(file = httr::upload_file("proteinGroups1.txt"), meta = httr::upload_file("proteinGroups1_meta.txt")))
# get all the paths of all files from the opencpu end, and locate the one, which is the report
# this step needs to be done in the script enviroment
paths <- strsplit(rawToChar(r$content), "\n")[[1]]
path_target <- paths[grep("output.html",paths)]
paths
# save/download the report file to local storage
# the file  "maxquant_result_summary.html" now is the report
curl::curl_download(paste0(url_server, path_target), "proteinGroups_summary.html")
r <- httr::POST(url_api, body = list(file = httr::upload_file("proteinGroups1.txt"), meta = httr::upload_file("proteinGroups1_meta.txt")))
# get all the paths of all files from the opencpu end, and locate the one, which is the report
# this step needs to be done in the script enviroment
paths <- strsplit(rawToChar(r$content), "\n")[[1]]
path_target <- paths[grep("output.html",paths)]
paths
# save/download the report file to local storage
# the file  "maxquant_result_summary.html" now is the report
curl::curl_download(paste0(url_server, path_target), "proteinGroups_summary.html")
url_api <- "http://206.12.91.148/ocpu/library/rmdocpu/R/render_peptides_file"
# get the root url
url_api_split <- strsplit(url_api, "/")[[1]]
url_server<- paste0(url_api_split[1],"//", url_api_split[3],"/")
# upload file and do the rendering
# in this case, the proteinGroups.txt is in the working dir. it can be anywhere with the path
# variable r is the returning information from the curl function
#r <- httr::POST(url_api, body = list(file = httr::upload_file("final_peptides.txt")))
r <- httr::POST(url_api, body = list(file = httr::upload_file("peptides3.txt"),meta = httr::upload_file("peptides3_meta.txt")))
r$status_code
# get all the paths of all files from the opencpu end, and locate the one, which is the report
# this step needs to be done in the script enviroment
paths <- strsplit(rawToChar(r$content), "\n")[[1]]
path_target <- paths[grep("output.html",paths)]
path_target
# save/download the report file to local storage
# the file  "maxquant_result_summary.html" now is the report
curl::curl_download(paste0(url_server, path_target), "peptides_summary.html")
url_api <- "http://206.12.91.148/ocpu/library/rmdocpu/R/render_peptides_file"
# get the root url
url_api_split <- strsplit(url_api, "/")[[1]]
url_server<- paste0(url_api_split[1],"//", url_api_split[3],"/")
# upload file and do the rendering
# in this case, the proteinGroups.txt is in the working dir. it can be anywhere with the path
# variable r is the returning information from the curl function
r <- httr::POST(url_api, body = list(file = httr::upload_file("peptides3.txt")))
#r <- httr::POST(url_api, body = list(file = httr::upload_file("peptides3.txt"),meta = httr::upload_file("peptides3_meta.txt")))
r$status_code
# get all the paths of all files from the opencpu end, and locate the one, which is the report
# this step needs to be done in the script enviroment
paths <- strsplit(rawToChar(r$content), "\n")[[1]]
path_target <- paths[grep("output.html",paths)]
path_target
# save/download the report file to local storage
# the file  "maxquant_result_summary.html" now is the report
curl::curl_download(paste0(url_server, path_target), "peptides_summary.html")
file <- "peptides3.txt"
meta <- "peptides3_meta.txt"
data_table  <- read.delim(file, header = TRUE,check.names = FALSE, stringsAsFactors = FALSE) # NOTE the read in options
myfile <- RCurl::getURL("https://raw.githubusercontent.com/ningzhibin/rmdocpu/master/inst/rmd/MQ_report_peptides.Rmd")
writeLines(myfile, con="input.Rmd");
meta_table <- read.delim(meta, header = TRUE, check.names = FALSE, stringsAsFactors = FALSE) #with meta file
rmarkdown::render("input.Rmd",output_format = "html_document", params = list(input_datatable =  data_table, meta_table = meta_table), output_file="output.html")
file <- "peptides1.txt"
meta <- "peptides1_meta.txt"
data_table  <- read.delim(file, header = TRUE,check.names = FALSE, stringsAsFactors = FALSE) # NOTE the read in options
myfile <- RCurl::getURL("https://raw.githubusercontent.com/ningzhibin/rmdocpu/master/inst/rmd/MQ_report_peptides.Rmd")
writeLines(myfile, con="input.Rmd");
if(!is.null(meta)){
meta_table <- read.delim(meta, header = TRUE, check.names = FALSE, stringsAsFactors = FALSE) #with meta file
rmarkdown::render("input.Rmd",output_format = "html_document", params = list(input_datatable =  data_table, meta_table = meta_table), output_file="output.html")
}else{
rmarkdown::render("input.Rmd",output_format = "html_document", params = list(input_datatable =  data_table), output_file="output.html")
}
meta_table <- read.delim(meta, header = TRUE, check.names = FALSE, stringsAsFactors = FALSE) #with meta file
meta
getwd()
meta
url_api
# upload file and do the rendering
# in this case, the proteinGroups.txt is in the working dir. it can be anywhere with the path
# variable r is the returning information from the curl function
#r <- httr::POST(url_api, body = list(file = httr::upload_file("peptides3.txt")))
r <- httr::POST(url_api, body = list(file = httr::upload_file("peptides3.txt"),meta = httr::upload_file("peptides3_meta.txt")))
r
?timeout
r <- httr::POST(url_api, body = list(file = httr::upload_file("peptides3.txt"),meta = httr::upload_file("peptides3_meta.txt")), timeout(200))
r$status_code
# upload file and do the rendering
# in this case, the proteinGroups.txt is in the working dir. it can be anywhere with the path
# variable r is the returning information from the curl function
#r <- httr::POST(url_api, body = list(file = httr::upload_file("peptides3.txt")))
r <- httr::POST(url_api, body = list(file = httr::upload_file("peptides3.txt"),meta = httr::upload_file("peptides3_meta.txt")), httr::timeout(200))
r$status_code
r
httr::timeout(200)
# upload file and do the rendering
# in this case, the proteinGroups.txt is in the working dir. it can be anywhere with the path
# variable r is the returning information from the curl function
#r <- httr::POST(url_api, body = list(file = httr::upload_file("peptides3.txt")))
r <- httr::POST(url_api, body = list(file = httr::upload_file("peptides3.txt"),meta = httr::upload_file("peptides3_meta.txt")), httr::timeout(1e+07))
# upload file and do the rendering
# in this case, the proteinGroups.txt is in the working dir. it can be anywhere with the path
# variable r is the returning information from the curl function
#r <- httr::POST(url_api, body = list(file = httr::upload_file("peptides3.txt")))
r <- httr::POST(url_api, body = list(file = httr::upload_file("peptides3.txt"),meta = httr::upload_file("peptides3_meta.txt")), httr::timeout(200000))
r
paths <- strsplit(rawToChar(r$content), "\n")[[1]]
path_target <- paths[grep("output.html",paths)]
path_target
# save/download the report file to local storage
# the file  "maxquant_result_summary.html" now is the report
curl::curl_download(paste0(url_server, path_target), "peptides_summary.html")
url_api <- "http://206.12.91.148/ocpu/library/rmdocpu/R/render_taxon_file"
# get the root url
url_api_split <- strsplit(url_api, "/")[[1]]
url_server<- paste0(url_api_split[1],"//", url_api_split[3],"/")
# upload file and do the rendering
# in this case, the proteinGroups.txt is in the working dir. it can be anywhere with the path
# variable r is the returning information from the curl function
r <- httr::POST(url_api, body = list(file = httr::upload_file("BuiltIn.taxa.refine.csv")))
# get all the paths of all files from the opencpu end, and locate the one, which is the report
# this step needs to be done in the script enviroment
paths <- strsplit(rawToChar(r$content), "\n")[[1]]
path_target <- paths[grep("output.html",paths)]
# save/download the report file to local storage
# the file  "maxquant_result_summary.html" now is the report
curl::curl_download(paste0(url_server, path_target), "report_taxonomy_summary.html")
r
url_api <- "http://206.12.91.148/ocpu/library/rmdocpu/R/render_function_file"
# get the root url
url_api_split <- strsplit(url_api, "/")[[1]]
url_server<- paste0(url_api_split[1],"//", url_api_split[3],"/")
# upload file and do the rendering
# in this case, the proteinGroups.txt is in the working dir. it can be anywhere with the path
# variable r is the returning information from the curl function
#r <- httr::POST(url_api, body = list(file = httr::upload_file("function_data_20190904.csv")))
r <- httr::POST(url_api, body = list(file = httr::upload_file("function_data_20190904.csv"), meta = httr::upload_file("function_meta_20190904.txt")))
r$status_code
# get all the paths of all files from the opencpu end, and locate the one, which is the report
# this step needs to be done in the script enviroment
paths <- strsplit(rawToChar(r$content), "\n")[[1]]
path_target <- paths[grep("output.html",paths)]
# save/download the report file to local storage
# the file  "maxquant_result_summary.html" now is the report
curl::curl_download(paste0(url_server, path_target), "function_summary.html")
?try
runApp('C:/Users/Figeys Lab/Dropbox/Project_MetaLab/shiny_apps/multivariable_analysis2')
library(selectize)
